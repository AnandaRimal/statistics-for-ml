# Famous Probability Distributions ğŸ“Š

Before diving into the distributions, lets talk about mathematical expectation first.

## ğŸ“‹ Table of Contents

1. [ğŸ¯ Mathematical Expectation](#-mathematical-expectation)
   - [ğŸŒŸ Why Do We Need Mathematical Expectation?](#-why-do-we-need-mathematical-expectation)
   - [ğŸ’¡ What Is Mathematical Expectation?](#-what-is-mathematical-expectation)
   - [ğŸ”¢ For Discrete Random Variables](#-for-discrete-random-variables)
   - [ğŸ“ˆ For Continuous Random Variables](#-for-continuous-random-variables)
   - [ğŸ“Œ Properties of Expectation](#-properties-of-expectation)
2. [ğŸ“Š Why Do We Need Variance and Standard Deviation?](#-why-do-we-need-variance-and-standard-deviation)
   - [ğŸ¯ Intuition](#-intuition)
   - [ğŸ’¡ What Is Variance?](#-what-is-variance)
   - [ğŸ§® Standard Deviation](#-standard-deviation)
   - [ğŸ² Example 1: Roll a Fair Die (1 to 6)](#-example-1-roll-a-fair-die-1-to-6)
   - [ğŸ¯ Interpretation](#-interpretation)
   - [ğŸ§  Real-Life Use Cases](#-real-life-use-cases)
3. [ğŸ® Example: Variance and std of Expectation](#-example-variance-and-std-of-expectation)
   - [ğŸ¯ Expectation = The Center](#-expectation--the-center)
   - [ğŸ® Game A](#-game-a)
   - [ğŸ® Game B](#-game-b)
   - [ğŸ§® Calculating Variance for Each Game](#-calculating-variance-for-each-game)
   - [ğŸ¯ Analogy: Archery](#-analogy-archery)
   - [ğŸ”‘ Final Takeaway](#-final-takeaway)
4. [ğŸ§  Expectation of Functions](#-expectation-of-functions-ex2-ex3-)
   - [ğŸ¯ How to Compute E(XÂ²)?](#-how-to-compute-exÂ²)
   - [ğŸ” Why Do We Care About E(XÂ²), E(XÂ³), ...?](#-why-do-we-care-about-exÂ²-exÂ³-)
   - [ğŸ”¢ Mini Example](#-mini-example)
5. [ğŸ“Š Discrete Probability Distribution](#-discrete-probability-distribution)
   - [ğŸ¯ Bernoulli Distribution](#-bernoulli-distribution)

---

## ğŸ¯ Mathematical Expectation

### ğŸŒŸ Why Do We Need Mathematical Expectation?

Imagine you're playing a game where you flip a coin:

- **If heads, you win â‚¹10.**
- **If tails, you lose â‚¹5.**

Would you play the game?  
To decide, you need a way to measure the average outcome if you played many times. This is where **expected value** comes in.  

ğŸ” *It helps us know the average outcome over the long run, even when results are random.*

### ğŸ’¡ What Is Mathematical Expectation?

**Mathematical Expectation** (or **Expected Value**) is the **weighted average of all possible values** a random variable can take, weighted by their probabilities.

---

#### ğŸ”¢ For Discrete Random Variables

Let's say a random variable \( X \) can take values \( x_1, x_2, ..., x_n \)  
with probabilities \( p_1, p_2, ..., p_n \).

\[
E(X) = x_1 \cdot p_1 + x_2 \cdot p_2 + \cdots + x_n \cdot p_n = \sum_{i=1}^{n} x_i \cdot p_i
\]

This means:

- Multiply each possible value \( x_i \) with its probability \( p_i \)
- Add them all up

---

#### ğŸ² Example 1: Roll a Fair Die

Each face (1 to 6) has equal probability \( \frac{1}{6} \). What's the expected value?

\[
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
\]

\[
E(X) = \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \frac{21}{6} = 3.5
\]

So, the **average outcome** in the long run is **3.5**  
(even though you never roll a 3.5).

---

#### ğŸ² Example 2: Coin Toss Game

- **Heads** â†’ Win â‚¹10  
- **Tails** â†’ Lose â‚¹5

Let \( X \) be the amount you win.

\[
E(X) = 10 \cdot \frac{1}{2} + (-5) \cdot \frac{1}{2} = \frac{10 - 5}{2} = \frac{5}{2} = 2.5
\]

You earn **â‚¹2.5 on average per toss**, so it's a **profitable game** in the long run.

---

#### ğŸ“ˆ For Continuous Random Variables

If \( X \) is a continuous variable with probability density function \( f(x) \):

\[
E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \, dx
\]

This is the same idea, but instead of adding, you're integrating over a curve.

---

#### ğŸ”§ Example: Uniform Distribution [0, 1]

Let's say \( X \sim U(0,1) \)

That means \( f(x) = 1 \) for \( x \in [0, 1] \)

\[
E(X) = \int_0^1 x \cdot 1 \, dx = \int_0^1 x \, dx = \left[ \frac{x^2}{2} \right]_0^1 = \frac{1}{2}
\]

So, the expected value is **0.5** â€” the midpoint.

---

#### âœ¨ Interpretation in Real Life

- ğŸ“Š **Insurance companies** use it to calculate average payouts.
- ğŸ’¹ **Economists** use it to find expected returns of investments.
- ğŸ° **Gamblers** use it to decide whether a game is worth playing.
- ğŸ¤– **AI/ML models** use it to find average loss (like in loss functions).

## ğŸ“Œ Properties of Expectation

### ğŸ”¢ Linearity

\[
E(aX + b) = aE(X) + b
\]

\[
E(X + Y) = E(X) + E(Y)
\]

âœ… *You can pull out constants and split addition.*  
âœ… *Even if \(X\) and \(Y\) are dependent!*  

### ğŸ” Expectation of a Constant

\[
E(c) = c
\]

âœ… *The expectation of a constant is the constant itself.*  

---

### ğŸ§  Common Misunderstanding

**Expected value is not necessarily the most likely value.**  

Example:  
You might expect to win **â‚¹2.5** on average, but you **never actually get â‚¹2.5** â€”  
you either win **â‚¹10** or lose **â‚¹5** in each game.

## ğŸ“Š Why Do We Need Variance and Standard Deviation?

You already know expected value tells us the average outcome. But what if I told you:

- **Two games have the same expected valueâ€¦**
- **But one is stable, and the other is risky and wild.**

How do we measure how much values vary around the average? That's where **variance and standard deviation** come in.

They tell us **how spread out or scattered the values of a random variable are** around the expected value.

### ğŸ¯ Intuition

- **Expectation** = Center of the target  
- **Variance/Standard Deviation** = How tightly the arrows are clustered or how far they scatter  

---

## ğŸ’¡ What Is Variance?

Let's say a random variable \( X \) has expected value \( E(X) = \mu \).  
Then the variance is:

\[
\text{Var}(X) = E[(X - \mu)^2]
\]

Which means:

1. Take how far each value is from the mean (\( X - \mu \)).
2. Square that difference (so negatives don't cancel out).
3. Take the **expected value** of that squared difference.
4. This tells you the **average squared deviation from the mean**.

---

### ğŸ§® Formula (for Discrete Random Variables)

If \( X \) takes values \( x_1, x_2, ..., x_n \) with probabilities \( p_1, p_2, ..., p_n \):

\[
\text{Var}(X) = \sum_{i=1}^{n} (x_i - \mu)^2 \cdot p_i
\]

Also, there's a **shortcut formula**:

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

We'll use this a lotâ€”it's easier to compute!

---

### ğŸ§® Standard Deviation

**Standard Deviation** is just the **square root of variance**:

\[
\text{SD}(X) = \sqrt{\text{Var}(X)}
\]

So variance is in **squared units**, while standard deviation brings it back to **original units**.

---

## ğŸ² Example 1: Roll a Fair Die (1 to 6)

We already found \( E(X) = 3.5 \).

Now let's calculate the variance:

### Step 1: Compute \( E(X^2) \)

\[
E(X^2) = \frac{1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2}{6} = \frac{1 + 4 + 9 + 16 + 25 + 36}{6} = \frac{91}{6} \approx 15.17
\]

### Step 2: Use the Shortcut Formula

\[
\text{Var}(X) = E(X^2) - [E(X)]^2 = 15.17 - (3.5)^2 = 15.17 - 12.25 = 2.92
\]

### Step 3: Compute Standard Deviation

\[
\text{SD}(X) = \sqrt{2.92} \approx 1.71
\]

This means:  
On average, the values deviate from the mean (3.5) by about **1.71 units**.

---

## ğŸ¯ Interpretation

- **If Variance = 0**, all values are the same (no variation).
- The **larger** the variance/SD, the **more spread out** the values.
- SD is **easier to interpret** than variance since it's in the same units.

---

## ğŸ§  Real-Life Use Cases

- ğŸ“‰ **Finance** â†’ Risk = variance of returns
- ğŸ¤– **Machine Learning** â†’ Variance helps measure how much a model's predictions fluctuate
- âš¡ **Physics** â†’ Measurement errors
- ğŸ« **Exams** â†’ SD tells how consistent scores are in a class

### ğŸ® Example: Variance and std of Expectation

## ğŸ¯ Expectation = The Center

Expected value tells you **on average**, how much you'll win or lose.

But **average alone doesn't tell the whole story**â€”it doesn't say how **consistent or risky** the outcomes are.

Let's compare two different games with the same expected value, but very different spreads.

---

## ğŸ® Game A:  
You **always** win â‚¹10.

- **With probability 1 â†’ â‚¹10**
- **Expected value:**
  
\[
E(X_A) = 10 \cdot 1 = 10
\]

âœ… **No variation. Very stable.**

---

## ğŸ® Game B:  
You win â‚¹0 or â‚¹20, **each with equal chance**.

| Outcome | Probability |
|---------|------------|
| â‚¹0      | 0.5        |
| â‚¹20     | 0.5        |

**Expected value:**

\[
E(X_B) = 0 \cdot 0.5 + 20 \cdot 0.5 = 10
\]

ğŸ“Œ Same expected value: â‚¹10  
ğŸ“ˆ But **Game B is more volatile**.

---

## ğŸ§  Key Question:  
If both games give â‚¹10 on average, **which one is more risky?**

- ğŸ‘‰ **Game A is completely stable.**
- ğŸ‘‰ **Game B is risky**â€”sometimes you get â‚¹0, sometimes â‚¹20.

To **measure risk**, we use **variance** and **standard deviation**.

---

## ğŸ§® Calculating Variance for Each Game:

âœ… **Game A (Always â‚¹10):**  

\[
\text{Var}(X_A) = E[(X - \mu)^2] = (10 - 10)^2 \cdot 1 = 0
\]

\[
\text{Standard Deviation} = \sqrt{0} = 0
\]

âœ”ï¸ **No variation at all.**

---

âœ… **Game B (â‚¹0 or â‚¹20):**  

\[
\text{Var}(X_B) = (0 - 10)^2 \cdot 0.5 + (20 - 10)^2 \cdot 0.5
\]

\[
= 100 \cdot 0.5 + 100 \cdot 0.5 = 50 + 50 = 100
\]

\[
\text{Standard Deviation} = \sqrt{100} = 10
\]

ğŸ¯ **Interpretation:**

- **Game A â†’** No surprise, **always â‚¹10 â†’ No risk**
- **Game B â†’** Big surprises! **Either â‚¹0 or â‚¹20 â†’ High risk**

---

## ğŸ¯ Analogy: Archery  
Imagine 5 archers aiming for the bullseye (**value = 10**):

### ğŸ¹ Archer A:  
Every arrow **hits the bullseye perfectly** â†’ scores: **10, 10, 10, 10, 10**

- ğŸ¯ **Average = 10**  
- ğŸ“ **Standard Deviation = 0 â†’ Perfect consistency**

### ğŸ¹ Archer B:  
Sometimes hits 0, sometimes hits 20 â†’ scores: **0, 20, 0, 20, 0**

- ğŸ¯ **Average = 10**  
- ğŸ“ **Standard Deviation = High â†’ Very inconsistent, risky**

---

## ğŸ”‘ Final Takeaway

- âœ… **Expectation tells you what you can expect on average.**
- âš ï¸ **Variance/Standard Deviation tells you how reliable that average is.**
- ğŸ“ˆ **High standard deviation = high unpredictability or risk.**
- ğŸ“‰ **Low standard deviation = stable and predictable.**

## ğŸ§  Expectation of Functions: \( E(X^2), E(X^3), \dots \)

We don't always want just \( E(X) \). Sometimes, we need:

- **\( E(X^2) \)** â†’ Used in **variance**
- **\( E(X^3), E(X^4) \)** â†’ Used in **skewness** and **kurtosis** (shape of the distribution)
- **\( E(aX + b) \)** â†’ Linear transformation expectation

---

## ğŸ¯ How to Compute \( E(X^2) \)?

If \( X \) has values \( x_1, x_2, ..., x_n \) with probabilities \( p_1, ..., p_n \):

\[
E(X^2) = \sum x_i^2 \cdot p_i
\]

For continuous cases:

\[
E(X^2) = \int x^2 f(x) \,dx
\]

---

## ğŸ” Why Do We Care About \( E(X^2), E(X^3), \dots \)?

- **\( E(X^2) \)** â†’ Needed to calculate variance:

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

- **\( E(X^3) \)** â†’ Measures **skewness** (is the distribution leaning left or right?)
- **\( E(X^4) \)** â†’ Measures **kurtosis** (how heavy the tails are)
- **In physics:** \( E(X^2) \) gives **moment of inertia**
- **In ML/Stats:** Used for **moment-generating functions**, feature engineering, etc.

---

## ğŸ”¢ Mini Example

Let \( X \) be a random variable with values **1, 2, 3** and probabilities **0.2, 0.5, 0.3**.

### Step 1: Compute \( E(X) \)

\[
E(X) = 1 \cdot 0.2 + 2 \cdot 0.5 + 3 \cdot 0.3 = 2.1
\]

### Step 2: Compute \( E(X^2) \)

\[
E(X^2) = 1^2 \cdot 0.2 + 2^2 \cdot 0.5 + 3^2 \cdot 0.3
\]

\[
= 0.2 + 2.0 + 2.7 = 4.9
\]

### Step 3: Compute Variance

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

\[
= 4.9 - (2.1)^2 = 4.9 - 4.41 = 0.49
\]

---

## ğŸ“Š Discrete Probability Distribution

Probabiity distribution of discrete random variabe having probability mass function is called discrete probability distribution. Different discrete probability distributions are 
- Bernoulli distribution
- Binomial distribution
- Poisson distribution 
- etc.
  
## ğŸ¯ Bernoulli Distribution
